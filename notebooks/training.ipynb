{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c038390",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "This notebook goes through an example of how to use Faeyon for model fine-tuning. We will be using a ViT model and fine-tune it using a custom dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba791423",
   "metadata": {},
   "source": [
    "## Initialize model\n",
    "\n",
    "We will use the pre-trained model -- . This model is available from the built-in configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cb84097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faeyon.models import load\n",
    "from faeyon.models.tasks import ClassifyTask\n",
    "from faeyon.training import Recipe\n",
    "import torch\n",
    "from torch import nn\n",
    "from faeyon import X, Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac6781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(\"vit/vit-base-patch16-224\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba2d8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224)\n",
    "pipeline = model >> ClassifyTask(num_hidden=768, num_labels=10, pooling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeefe939",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x >> pipeline >> X.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faeyon.magic.spells.Serials at 0x7f98572fd910>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = X >> Op(X + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72091c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('__add__', (1,), {})\n"
     ]
    }
   ],
   "source": [
    "for item in X + 1:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63529b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faeyon.models.core import _read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9aa4910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, state = _read_yaml(\"try.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c568e42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__call__', (), {})]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data._buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "abedaa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['cls_token', 'patch_embedding.weight', 'patch_embedding.bias', 'pos_embeddings.embeddings', 'pos_embeddings.non_positional', 'blocks.lnorm_in.0.weight', 'blocks.lnorm_in.0.bias', 'blocks.lnorm_in.1.weight', 'blocks.lnorm_in.1.bias', 'blocks.lnorm_in.2.weight', 'blocks.lnorm_in.2.bias', 'blocks.lnorm_in.3.weight', 'blocks.lnorm_in.3.bias', 'blocks.lnorm_in.4.weight', 'blocks.lnorm_in.4.bias', 'blocks.lnorm_in.5.weight', 'blocks.lnorm_in.5.bias', 'blocks.lnorm_in.6.weight', 'blocks.lnorm_in.6.bias', 'blocks.lnorm_in.7.weight', 'blocks.lnorm_in.7.bias', 'blocks.lnorm_in.8.weight', 'blocks.lnorm_in.8.bias', 'blocks.lnorm_in.9.weight', 'blocks.lnorm_in.9.bias', 'blocks.lnorm_in.10.weight', 'blocks.lnorm_in.10.bias', 'blocks.lnorm_in.11.weight', 'blocks.lnorm_in.11.bias', 'blocks.lnorm_out.0.weight', 'blocks.lnorm_out.0.bias', 'blocks.lnorm_out.1.weight', 'blocks.lnorm_out.1.bias', 'blocks.lnorm_out.2.weight', 'blocks.lnorm_out.2.bias', 'blocks.lnorm_out.3.weight', 'blocks.lnorm_out.3.bias', 'blocks.lnorm_out.4.weight', 'blocks.lnorm_out.4.bias', 'blocks.lnorm_out.5.weight', 'blocks.lnorm_out.5.bias', 'blocks.lnorm_out.6.weight', 'blocks.lnorm_out.6.bias', 'blocks.lnorm_out.7.weight', 'blocks.lnorm_out.7.bias', 'blocks.lnorm_out.8.weight', 'blocks.lnorm_out.8.bias', 'blocks.lnorm_out.9.weight', 'blocks.lnorm_out.9.bias', 'blocks.lnorm_out.10.weight', 'blocks.lnorm_out.10.bias', 'blocks.lnorm_out.11.weight', 'blocks.lnorm_out.11.bias', 'blocks.linear1.0.weight', 'blocks.linear1.0.bias', 'blocks.linear1.1.weight', 'blocks.linear1.1.bias', 'blocks.linear1.2.weight', 'blocks.linear1.2.bias', 'blocks.linear1.3.weight', 'blocks.linear1.3.bias', 'blocks.linear1.4.weight', 'blocks.linear1.4.bias', 'blocks.linear1.5.weight', 'blocks.linear1.5.bias', 'blocks.linear1.6.weight', 'blocks.linear1.6.bias', 'blocks.linear1.7.weight', 'blocks.linear1.7.bias', 'blocks.linear1.8.weight', 'blocks.linear1.8.bias', 'blocks.linear1.9.weight', 'blocks.linear1.9.bias', 'blocks.linear1.10.weight', 'blocks.linear1.10.bias', 'blocks.linear1.11.weight', 'blocks.linear1.11.bias', 'blocks.linear2.0.weight', 'blocks.linear2.0.bias', 'blocks.linear2.1.weight', 'blocks.linear2.1.bias', 'blocks.linear2.2.weight', 'blocks.linear2.2.bias', 'blocks.linear2.3.weight', 'blocks.linear2.3.bias', 'blocks.linear2.4.weight', 'blocks.linear2.4.bias', 'blocks.linear2.5.weight', 'blocks.linear2.5.bias', 'blocks.linear2.6.weight', 'blocks.linear2.6.bias', 'blocks.linear2.7.weight', 'blocks.linear2.7.bias', 'blocks.linear2.8.weight', 'blocks.linear2.8.bias', 'blocks.linear2.9.weight', 'blocks.linear2.9.bias', 'blocks.linear2.10.weight', 'blocks.linear2.10.bias', 'blocks.linear2.11.weight', 'blocks.linear2.11.bias', 'blocks.attention.0.in_proj_weight', 'blocks.attention.0.in_proj_bias', 'blocks.attention.0.out_proj.weight', 'blocks.attention.0.out_proj.bias', 'blocks.attention.1.in_proj_weight', 'blocks.attention.1.in_proj_bias', 'blocks.attention.1.out_proj.weight', 'blocks.attention.1.out_proj.bias', 'blocks.attention.2.in_proj_weight', 'blocks.attention.2.in_proj_bias', 'blocks.attention.2.out_proj.weight', 'blocks.attention.2.out_proj.bias', 'blocks.attention.3.in_proj_weight', 'blocks.attention.3.in_proj_bias', 'blocks.attention.3.out_proj.weight', 'blocks.attention.3.out_proj.bias', 'blocks.attention.4.in_proj_weight', 'blocks.attention.4.in_proj_bias', 'blocks.attention.4.out_proj.weight', 'blocks.attention.4.out_proj.bias', 'blocks.attention.5.in_proj_weight', 'blocks.attention.5.in_proj_bias', 'blocks.attention.5.out_proj.weight', 'blocks.attention.5.out_proj.bias', 'blocks.attention.6.in_proj_weight', 'blocks.attention.6.in_proj_bias', 'blocks.attention.6.out_proj.weight', 'blocks.attention.6.out_proj.bias', 'blocks.attention.7.in_proj_weight', 'blocks.attention.7.in_proj_bias', 'blocks.attention.7.out_proj.weight', 'blocks.attention.7.out_proj.bias', 'blocks.attention.8.in_proj_weight', 'blocks.attention.8.in_proj_bias', 'blocks.attention.8.out_proj.weight', 'blocks.attention.8.out_proj.bias', 'blocks.attention.9.in_proj_weight', 'blocks.attention.9.in_proj_bias', 'blocks.attention.9.out_proj.weight', 'blocks.attention.9.out_proj.bias', 'blocks.attention.10.in_proj_weight', 'blocks.attention.10.in_proj_bias', 'blocks.attention.10.out_proj.weight', 'blocks.attention.10.out_proj.bias', 'blocks.attention.11.in_proj_weight', 'blocks.attention.11.in_proj_bias', 'blocks.attention.11.out_proj.weight', 'blocks.attention.11.out_proj.bias', 'lnorm.weight', 'lnorm.bias'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5774a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
