{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c038390",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "This notebook goes through an example of how to use Faeyon for model fine-tuning. We will be using a ViT model and fine-tune it using a custom dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba791423",
   "metadata": {},
   "source": [
    "## Initialize model\n",
    "\n",
    "We will use the pre-trained model -- . This model is available from the built-in configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb84097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faeyon.models import Pipeline\n",
    "from faeyon.models.tasks import ClassifyTask\n",
    "from faeyon.training import Recipe\n",
    "from faeyon.io import load\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from faeyon import X, Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac6781f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PosixPath' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvit/vit-base-patch16-224\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/faeyon-ml/faeyon/faeyon/io.py:296\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, load_state, module, cache, trust_code, overrides, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mLoads a model from a YAML configuration file or a pytorch serialized file. Can also be a \u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03mbuiltin model configuration, which is a YAML file in the package configs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m \u001b[33;03mload(ModelClass, \"model.pt\"/model.yaml) -- should only contain the state dict\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m | PathLike):\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_from_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, nn.Module):\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(load_state, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/faeyon-ml/faeyon/faeyon/io.py:262\u001b[39m, in \u001b[36m_load_from_files\u001b[39m\u001b[34m(config_file, load_state, trust_code, cache, module, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m     state = _read_pt(load_state, cache, **kwargs)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m state_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     state = \u001b[43m_read_pt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    265\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo state found in the yaml file or the .pt file. Please provide a path for the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    266\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstate file, or update the YAML file to include the state file path.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    267\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/faeyon-ml/faeyon/faeyon/io.py:201\u001b[39m, in \u001b[36m_read_pt\u001b[39m\u001b[34m(name, cache, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# Only wrap with filecache if protocol is remote and caching is desired\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_remote \u001b[38;5;129;01mand\u001b[39;00m cache:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     fs = \u001b[43mfsspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfilecache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_protocol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_files\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpiry_time\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fs.open(name, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    210\u001b[39m     data = torch.load(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/faeyon-ml/.venv/lib/python3.13/site-packages/fsspec/registry.py:322\u001b[39m, in \u001b[36mfilesystem\u001b[39m\u001b[34m(protocol, **storage_options)\u001b[39m\n\u001b[32m    315\u001b[39m     warnings.warn(\n\u001b[32m    316\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33marrow_hdfs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m protocol has been deprecated and will be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    317\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mremoved in the future. Specify it as \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhdfs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    318\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    319\u001b[39m     )\n\u001b[32m    321\u001b[39m \u001b[38;5;28mcls\u001b[39m = get_filesystem_class(protocol)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/faeyon-ml/.venv/lib/python3.13/site-packages/fsspec/spec.py:81\u001b[39m, in \u001b[36m_Cached.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._cache[token]\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     obj = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Setting _fs_token here causes some static linters to complain.\u001b[39;00m\n\u001b[32m     83\u001b[39m     obj._fs_token_ = token\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/faeyon-ml/.venv/lib/python3.13/site-packages/fsspec/implementations/cached.py:137\u001b[39m, in \u001b[36mCachingFileSystem.__init__\u001b[39m\u001b[34m(self, target_protocol, cache_storage, cache_check, check_files, expiry_time, target_options, fs, same_names, compression, cache_mapper, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m         storage = cache_storage\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m os.makedirs(\u001b[43mstorage\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    138\u001b[39m \u001b[38;5;28mself\u001b[39m.storage = storage\n\u001b[32m    139\u001b[39m \u001b[38;5;28mself\u001b[39m.kwargs = target_options \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[31mTypeError\u001b[39m: 'PosixPath' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model = load(\"vit/vit-base-patch16-224\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2d8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    model=model,\n",
    "    task=ClassifyTask(num_hidden=768, num_labels=1000, pooling=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abedaa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0e4900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "462a3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ViTMAEForPreTraining, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8ae59c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056019356086420c83996f32be7780b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/217 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2177c6a9f01d490d92c6b38c91c68960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457f3fbbc110483f8f28663acb27dcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained('facebook/vit-mae-large')\n",
    "model = ViTMAEForPreTraining.from_pretrained('facebook/vit-mae-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dca001f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at facebook/vit-mae-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained('facebook/vit-mae-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2014b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6f43e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07ae8a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6318, 0.1906, 0.5343, 0.2344, 0.9375, 0.7655, 0.5219, 0.0964],\n",
       "        [0.3034, 0.3704, 0.3058, 0.0647, 0.6987, 0.5331, 0.5707, 0.7920],\n",
       "        [0.2304, 0.2124, 0.7848, 0.7270, 0.9876, 0.4346, 0.3693, 0.8762]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "seq_length = 8\n",
    "noise = torch.rand(batch_size, seq_length)\n",
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_masking(sequence, noise=None):\n",
    "    mask_ratio = 0.75\n",
    "    batch_size, seq_length, dim = sequence.shape\n",
    "    len_keep = int(seq_length * (1 - mask_ratio))\n",
    "\n",
    "    if noise is None:\n",
    "        noise = torch.rand(batch_size, seq_length, device=sequence.device)  # noise in [0, 1]\n",
    "\n",
    "    # sort noise for each sample\n",
    "    ids_shuffle = torch.argsort(noise, dim=1).to(sequence.device)  # ascend: small is keep, large is remove\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1).to(sequence.device)\n",
    "\n",
    "    # keep the first subset\n",
    "    ids_keep = ids_shuffle[:, :len_keep]\n",
    "    sequence_unmasked = torch.gather(sequence, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, dim))\n",
    "\n",
    "    # generate the binary mask: 0 is keep, 1 is remove\n",
    "    mask = torch.ones([batch_size, seq_length], device=sequence.device)\n",
    "    mask[:, :len_keep] = 0\n",
    "    # unshuffle to get the binary mask\n",
    "    mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "\n",
    "    return sequence_unmasked, mask, ids_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64917c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9579e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = torch.randn(batch_size, seq_length, 4)\n",
    "\n",
    "res, mask, ids_restore = random_masking(sequence, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbd0197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3f09ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 4\n",
    "grid_h = np.arange(grid_size, dtype=np.float32)\n",
    "grid_w = np.arange(grid_size, dtype=np.float32)\n",
    "grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "#grid = np.stack(grid, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42f4782d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1., 2., 3.],\n",
       "        [0., 1., 2., 3.],\n",
       "        [0., 1., 2., 3.],\n",
       "        [0., 1., 2., 3.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.]], dtype=float32))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29f53cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 1., 2., 3.],\n",
       "         [0., 1., 2., 3.],\n",
       "         [0., 1., 2., 3.],\n",
       "         [0., 1., 2., 3.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3.]]]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(grid, axis=0).reshape([2, 1, grid_size, grid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db02479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
