{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ee7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ViTForImageClassification, AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from collections import defaultdict\n",
    "\n",
    "from faeyon.io import load\n",
    "from faeyon import X\n",
    "\n",
    "repo = \"google/vit-base-patch16-224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37596618",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = ViTForImageClassification.from_pretrained(repo)\n",
    "hf_model.eval()\n",
    "hf_model.cuda()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f25428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(\"vit/vit-base-patch16-224\", cache=True)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3380032",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(repo)\n",
    "imagenet = load_dataset(\"ILSVRC/imagenet-1k\", trust_remote_code=True)\n",
    "inputs = image_processor(\n",
    "    images=imagenet[\"train\"][0][\"image\"],\n",
    "    return_tensors=\"np\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c08d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.tensor(inputs[\"pixel_values\"]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "hf_y = hf_model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "y = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.4/3.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfdf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_y = hf_model(img)\n",
    "y = model(img)\n",
    "torch.allclose(hf_y.logits,  y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243befa",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6845a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and compare\n",
    "def analyze_profile(pr, ndata = sorted([(stat.code, stat.callcount, stat.inlinetime) for stat in pr.getstats()], key=lambda x: x[1], reverse=True)ame):\n",
    "    \"\"\"Analyze a profile and return statistics\"\"\"\n",
    "    stats = pr.getstats()\n",
    "    total_time = sum(stat.totaltime for stat in stats)\n",
    "    \n",
    "    # Group by module\n",
    "    by_module = defaultdict(lambda: {\"time\": 0.0, \"calls\": 0, \"functions\": []})\n",
    "    \n",
    "    for stat in stats:\n",
    "        if stat.code and not isinstance(stat.code, str):\n",
    "            filename = stat.code.co_filename\n",
    "            func_name = stat.code.co_name\n",
    "            module = filename.split('/')[-1] if '/' in filename else filename.split('\\\\')[-1]\n",
    "            \n",
    "            by_module[module][\"time\"] += stat.totaltime\n",
    "            by_module[module][\"calls\"] += stat.callcount\n",
    "            if stat.totaltime > 0.0001:  # Only track functions taking > 0.1ms\n",
    "                by_module[module][\"functions\"].append({\n",
    "                    \"name\": func_name,\n",
    "                    \"time\": stat.totaltime,\n",
    "                    \"calls\": stat.callcount\n",
    "                })\n",
    "    \n",
    "    # Sort functions by time\n",
    "    for module in by_module:\n",
    "        by_module[module][\"functions\"].sort(key=lambda x: x[\"time\"], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        \"total_time\": total_time,\n",
    "        \"by_module\": dict(by_module)\n",
    "    }\n",
    "\n",
    "_ = model(img)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Profile Hugging Face model\n",
    "with cProfile.Profile() as pr:\n",
    "    y = model(img)\n",
    "\n",
    "pr.print_stats(sort=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b18d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 2, 3] >> X[X[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9996c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted([(stat.code, stat.callcount, stat.inlinetime) for stat in pr.getstats()], key=lambda x: x[1], reverse=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e482a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faeyon import X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f002dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "10 >> square(X)\n",
    "\n",
    "torch.mean(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 2] >> [3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9f6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c9e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0180f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spells = [stat for stat in stats if not isinstance(stat.code, str) and \"spells\" in stat.code.co_filename]\n",
    "faek = [stat for stat in stats if not isinstance(stat.code, str) and \"faek\" in stat.code.co_filename]\n",
    "spells = sorted(spells, key=lambda x: x.inlinetime * x.reccallcount, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf43d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "spells[0].calls#.code.co_firstlineno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f364eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top-level function (usually the model's __call__ or forward)\n",
    "top_level = max(stats, key=lambda s: s.totaltime if s.code else 0)\n",
    "total_time = top_level.totaltime  # âœ… This is the actual total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691be301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lines  = []\n",
    "for s in spells:\n",
    "    lines.append(s.code.co_qualname)\n",
    "\n",
    "Counter(lines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
